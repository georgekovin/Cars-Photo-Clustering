{"cells":[{"cell_type":"markdown","metadata":{},"source":["# <center> Кластеризация изображений транспортных средств"]},{"cell_type":"markdown","metadata":{},"source":["## Импорт библиотек"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-04T12:56:27.447874Z","iopub.status.busy":"2023-09-04T12:56:27.447447Z","iopub.status.idle":"2023-09-04T12:56:30.190327Z","shell.execute_reply":"2023-09-04T12:56:30.189218Z","shell.execute_reply.started":"2023-09-04T12:56:27.447839Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.cluster import MiniBatchKMeans, AgglomerativeClustering, DBSCAN\n","from sklearn.mixture import GaussianMixture\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import warnings \n","import pickle\n","\n","plt.style.use('ggplot')\n","warnings.simplefilter(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Знакомство со структурой данных"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-04T12:56:30.192466Z","iopub.status.busy":"2023-09-04T12:56:30.191971Z","iopub.status.idle":"2023-09-04T12:57:28.655783Z","shell.execute_reply":"2023-09-04T12:57:28.654622Z","shell.execute_reply.started":"2023-09-04T12:56:30.192438Z"},"trusted":true},"outputs":[],"source":["desc_path = 'data/descriptors/'\n","\n","effnet_data = pickle.load(open(desc_path+'efficientnet-b7.pickle', 'rb')) \n","osnet_data = pickle.load(open(desc_path+'osnet.pickle', 'rb'))\n","vdc_color_data = pickle.load(open(desc_path+'vdc_color.pickle', 'rb'))\n","vdc_type_data = pickle.load(open(desc_path+'vdc_type.pickle', 'rb'))\n","\n","effnet_name = 'EfficientNet'\n","osnet_name = 'OSNet'\n","vdc_color_name = 'VDC color regression'\n","vdc_type_name = 'VDC type classification'\n","\n","additional_message = ''\n","\n","print_data = lambda name, data: print(f'{name}{additional_message}:\\n {data}', '\\n', \n","                                      f'{data.shape[0]} rows, {data.shape[1]} columns')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print_data(effnet_name, effnet_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print_data(osnet_name, osnet_data) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print_data(vdc_color_name, vdc_color_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print_data(vdc_type_name, vdc_type_data) "]},{"cell_type":"markdown","metadata":{},"source":["> *Посмотрев на размерности каждой из заданных матриц, можно сказать, что нейросеть EfficientNet описывает изображения наиболее подробным образом - на 2560 дескрипторов. На мой взгляд, в конечном итоге, именно на дескрипторах этой модели кластеризация будет наиболее точной.*"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-04T12:57:28.657383Z","iopub.status.busy":"2023-09-04T12:57:28.657069Z","iopub.status.idle":"2023-09-04T12:57:29.241593Z","shell.execute_reply":"2023-09-04T12:57:29.240452Z","shell.execute_reply.started":"2023-09-04T12:57:28.657356Z"},"trusted":true},"outputs":[],"source":["img_paths = pd.read_csv('data/images_paths.csv')\n","\n","img_paths.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img_paths['paths'] = ('data/raw_data/' + \n","                      img_paths['paths']\n","                      .apply(lambda x: x.replace('\\\\', '/')))\n","\n","img_paths.head()"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Преобразование, очистка и анализ данных"]},{"cell_type":"markdown","metadata":{},"source":["Признаки, найденные с помощью некоторых моделей, исчисляются тысячами, что довольно много. Производить кластеризацию на таком большом количестве признаков, которые были сформированы исходными моделями глубокого обучения, довольно сложно и затратно по времени. \n","\n","Понизим размерность исходных дескрипторов с помощью соответствующих методов. Можно уменьшить размерность входных данных до 100 или 200 признаков — этого будет достаточно, чтобы произвести кластеризацию."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-04T12:57:29.244497Z","iopub.status.busy":"2023-09-04T12:57:29.244149Z","iopub.status.idle":"2023-09-04T12:57:29.249502Z","shell.execute_reply":"2023-09-04T12:57:29.248267Z","shell.execute_reply.started":"2023-09-04T12:57:29.244467Z"},"trusted":true},"outputs":[],"source":["RS = 12 # random_state\n","additional_message = ' standardised and decomposed'\n","\n","def standardise_and_decompose(data, n_components):\n","    scaler = StandardScaler()\n","    data_scaled = scaler.fit_transform(data)\n","    \n","    decomposer = PCA(n_components=n_components, random_state=RS)\n","    data_decomposed = decomposer.fit_transform(data_scaled)\n","    \n","    return data_decomposed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_effnet = standardise_and_decompose(effnet_data, n_components=200) \n","\n","print_data(effnet_name, X_effnet) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_osnet = standardise_and_decompose(osnet_data, n_components=100)\n","\n","print_data(osnet_name, X_osnet) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_vdc_color = standardise_and_decompose(vdc_color_data, n_components=50)\n","\n","print_data(vdc_color_name, X_vdc_color)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_vdc_type = standardise_and_decompose(vdc_type_data, n_components=100)\n","\n","print_data(vdc_type_name, X_vdc_type) "]},{"cell_type":"markdown","metadata":{},"source":["## 3. Моделирование и оценка качества модели"]},{"cell_type":"markdown","metadata":{},"source":["После предобработки исходных данных произведите кластеризацию для каждого набора дескрипторов.\n","\n","Для решения задачи используйте несколько различных методов, подобрав оптимальное количество кластеров для каждого метода и варианта дескрипторов.\n","\n","В качестве метрики для подбора оптимального количества кластеров используйте внутренние меры:\n","* индекс Калински — Харабаса (`calinski_harabasz_score`) \n","* индекс Дэвиса — Болдина (`davies_bouldin_score`)"]},{"cell_type":"markdown","metadata":{},"source":["#### 1. Визуализация результатов кластеризации"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_samples_images(label, data=img_paths, nrows=3, ncols=3):\n","    \"\"\"Функция для визуализации нескольких \n","       случайных изображений из кластера cluster_label.\n","       Пути до изображений и метки кластеров должны быть \n","       представлены в виде DataFrame со столбцами \"paths\" и \"cluster\".\n","\n","    Args:\n","        data (DataFrame): таблица с разметкой изображений и соответствующих им кластеров\n","        cluster_label (int): номер кластера изображений\n","        nrows (int, optional): количество изображений по строкам таблицы (по умолчанию 3)\n","        ncols (int, optional): количество изображений по столбцам (по умолчанию 3)\n","    \"\"\"\n","    \n","    # Фильтруем данные по номеру кластера\n","    samples_indexes = np.array(data[data['cluster'] == label].index)\n","    # Перемешиваем результаты\n","    np.random.shuffle(samples_indexes)\n","    # Составляем пути до изображений\n","    paths = data.loc[samples_indexes, 'paths']\n","\n","    # Создаём фигуру и набор координатных плоскостей\n","    fig, axes = plt.subplots(nrows, ncols, figsize=(8, 5))\n","    fig.suptitle(f\"Cluster {label}\", fontsize=16)\n","    \n","    # Создаём циклы по строкам и столбцам в таблице с координатными плоскостями\n","    for i in range(nrows):\n","        for j in range(ncols):\n","            # Определяем индекс пути до изображения\n","            path_idx = i * ncols + j\n","            if path_idx >= len(paths):\n","                break\n","                \n","            # Извлекаем путь до изображения\n","            path = paths.iloc[path_idx]\n","            \n","            # Читаем изображение\n","            img = plt.imread(path)\n","            \n","            # Убираем пометки координатных осей\n","            axes[i,j].axis('off')\n","            # Отображаем его на соответствующей координатной плоскости\n","            axes[i,j].imshow(img)\n","\n","\n","get_sample = lambda X, n=5000: pd.DataFrame(X).sample(n, \n","                                                      random_state=RS, \n","                                                      ignore_index=False)\n","\"\"\"_summary_\"\"\"\n","\n","\n","def clusters_visualiser(X, y, title, n_components=3, data=img_paths):\n","    \"\"\"_summary_\n","\n","    Args:\n","        X (_type_): _description_\n","        y (_type_): _description_\n","        title (_type_): _description_\n","        n_components (_type_): _description_\n","\n","    Returns:\n","        None: _description_\n","    \"\"\"\n","    \n","    tsne_decomposer = TSNE(n_components=n_components, \n","                           random_state=RS, \n","                           n_jobs=-1)\n","    \n","    X_tsne = tsne_decomposer.fit_transform(X)\n","    \n","    tsne_data = pd.DataFrame(X_tsne, columns=['x', 'y', 'z'])\n","    tsne_data['label'] = y\n","    \n","    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n","    palette = 'muted'\n","    \n","    sns.scatterplot(tsne_data, \n","                    x='x', y='y', hue='label', \n","                    palette=palette, \n","                    ax=ax[0])\n","    sns.scatterplot(tsne_data, \n","                    x='y', y='z', hue='label', \n","                    palette=palette, \n","                    ax=ax[1])\n","    sns.scatterplot(tsne_data, \n","                    x='x', y='z', hue='label', \n","                    palette=palette, \n","                    ax=ax[2])\n","\n","    fig.suptitle(title)\n","    fig.show()\n","    \n","    data['cluster'] = y\n","\n","    for i in np.unique(y):\n","        plot_samples_images(i, data)"]},{"cell_type":"markdown","metadata":{},"source":["#### 2. Настройка параметров алгоритма "]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def tune_one_param(X, \n","                   model, \n","                   p_name, \n","                   p_space):\n","    \n","    space_list = []\n","    chs_list = []\n","    dbs_list = []\n","\n","    for param in p_space:\n","        model.set_params(**{p_name: param})\n","        y = model.fit_predict(X)\n","        \n","        if len(np.unique(y)) == 1:\n","            continue # на случай если модель, например DBSCAN, покажет один единственный кластер\n","        else:\n","            space_list.append(param)\n","            chs_list.append(calinski_harabasz_score(X, y))\n","            dbs_list.append(davies_bouldin_score(X, y))\n","            \n","    scores_data = pd.DataFrame({'chs': chs_list, \n","                                'dbs': dbs_list}, \n","                               index=space_list)\n","    \n","    chs_param = (scores_data\n","                 .sort_values('chs', ascending=False)\n","                 .index[0])\n","    dbs_param = (scores_data\n","                 .sort_values('dbs', ascending=True)\n","                 .index[0])\n","    \n","    return {'Calinski-Harabasz': chs_param, \n","            'Davies-Bouldin': dbs_param} \n","\n","\n","def iterative_train(data, \n","                    model,  \n","                    cut_size=5000):\n","    i_from = list(range(0, \n","                        data.shape[0], \n","                        cut_size))\n","    i_to = list(range(cut_size, \n","                      data.shape[0], \n","                      cut_size)) + [data.shape[0]]\n","\n","    y = []\n","    \n","    for i, j in zip(i_from, i_to):\n","        X = data[i:j]\n","        model.fit(X)\n","        \n","        [y.append(label) for label in model.labels_]\n","    \n","    return pd.Series(y) \n","\n","\n","def show_opt_clusters(X, \n","                      title, \n","                      model, \n","                      p_name, \n","                      p_space):\n","    \n","    X_sample = get_sample(X)\n","    scores_params = tune_one_param(X_sample, \n","                                   model, \n","                                   p_name, \n","                                   p_space)\n","    \n","    print(f\"Got optimal '{p_name}' values:\\n{scores_params}\\n\")\n","    \n","    for score, param in scores_params.items():\n","        model.set_params(**{p_name: param})\n","        y = model.fit_tredict(X_sample)\n","        \n","        n_clusters = len(np.unique(y))\n","        print(f'Got {n_clusters} clusters according to {score} score with model:\\n{model}\\n')\n","\n","        clusters_visualiser(X, y, title+f' ({score})')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["eps_space = (np.linspace(0.01, 100, 100, \n","                         dtype=float)\n","             .round(2)\n","             .tolist())\n","\n","    \n","opt_dbscan = lambda X, title: show_opt_clusters(X, \n","                                                title, \n","                                                model=DBSCAN(n_jobs=-1), \n","                                                p_name='eps', \n","                                                p_space=eps_space)"]},{"cell_type":"markdown","metadata":{},"source":["#### 3. Визуализация полученных кластеров и их изображений"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["opt_dbscan(X_effnet, effnet_name) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["opt_dbscan(X_osnet, osnet_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["opt_dbscan(X_vdc_color, vdc_color_name) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["opt_dbscan(X_vdc_type, vdc_type_name) "]},{"cell_type":"markdown","metadata":{},"source":["## 3.1 Метод MiniBatchKMeans"]},{"cell_type":"markdown","metadata":{},"source":["Поскольку исходных данных много, могут возникнуть проблемы с оперативной памятью и скоростью работы, например при использовании классического алгоритма `K-means`, можно воспользоваться реализацией `MiniBatchKMeans`. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-04T13:00:22.741548Z","iopub.status.busy":"2023-09-04T13:00:22.741157Z","iopub.status.idle":"2023-09-04T13:02:13.309018Z","shell.execute_reply":"2023-09-04T13:02:13.307549Z","shell.execute_reply.started":"2023-09-04T13:00:22.741512Z"},"trusted":true},"outputs":[],"source":["def get_clustering_scores(model, data, c_range, rs=None):\n","    chs_list = []\n","    dbs_list = []\n","    \n","    for c in c_range:\n","        \n","        if rs is not None:\n","            model_ = model(c, random_state=RS)    \n","        else: \n","            model_ = model(c)\n","        \n","        labels = model_.fit_predict(data)\n","        \n","        chs_list.append(calinski_harabasz_score(data, labels))\n","        dbs_list.append(davies_bouldin_score(data, labels))\n","    \n","    return chs_list, dbs_list\n","\n","\n","def get_n_clusters(df, aggf):\n","    c_dict = {}\n","    \n","    for col in df.columns:\n","        if aggf == 'max':\n","            c_dict[col] = (df[col]\n","                           .sort_values(ascending=False)\n","                           .index[0])\n","        if aggf == 'min':\n","            c_dict[col] = (df[col]\n","                           .sort_values(ascending=True)\n","                           .index[0])\n","        \n","    return c_dict"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["datasets = {'efficientnet': X_effnet, \n","            'osnet': X_osnet, \n","            'vdc_color_reg': X_vdc_color, \n","            'vdc_type_cl': X_vdc_type}\n","\n","clusters = list(range(2, 11))\n","\n","\n","def show_clusters_and_scores(model,\n","                             datasets=datasets, \n","                             clusters=clusters, \n","                             rs=None, \n","                             sample_data=False):\n","    \n","    chs_df = pd.DataFrame(index=clusters)\n","    chs_name = 'Calinski-Harabasz'\n","    \n","    dbs_df = pd.DataFrame(index=clusters) \n","    dbs_name = 'Davies-Bouldin'\n","    \n","    for name, data in datasets.items():\n","        if sample_data:\n","            data = get_sample(data)\n","        \n","        if rs is not None:\n","            chs_df[name] = get_clustering_scores(model, data, clusters, rs)[0]\n","            dbs_df[name] = get_clustering_scores(model, data, clusters, rs)[1]\n","        else: \n","            chs_df[name] = get_clustering_scores(model, data, clusters)[0]\n","            dbs_df[name] = get_clustering_scores(model, data, clusters)[1]\n","    \n","    metsics = pd.DataFrame(data=[get_n_clusters(chs_df, 'max'), \n","                                 get_n_clusters(dbs_df, 'min')], \n","                           index=[chs_name, dbs_name])\n","    \n","    return metsics\n","\n","\n","show_clusters_and_scores(MiniBatchKMeans, rs=RS)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["additional_message = ' labels and their counts'\n","\n","print_series = lambda name, data: print(f'{name}{additional_message}:\\n {data}', '\\n', \n","                                        pd.Series(data).value_counts().to_dict(), '\\n')\n","\n","\n","def train_minibatchkmeans(X, n):\n","    mbkm = MiniBatchKMeans(n_clusters=n, random_state=RS)\n","    y = mbkm.fit_predict(X)\n","    \n","    return y\n","\n","\n","def n_visualiser(X, n_clusters, train_func, title, n_components=3):\n","    y = train_func(X, n_clusters)\n","    print_series(title, y)\n","    \n","    clusters_visualiser(X, y, title, n_components)"]},{"cell_type":"markdown","metadata":{},"source":["### Интерпретация кластеров"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clusters_visualiser(X_effnet, y_effnet, effnet_name) "]},{"cell_type":"markdown","metadata":{},"source":["*Разница между кластерами очень слабая, так как на графике точки очень плотно расположены друг к другу и образуют четкий эллипс в его центре.*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clusters_visualiser(X_osnet, y_osnet, osnet_name) "]},{"cell_type":"markdown","metadata":{},"source":["0. прочие\n","1. белые сзади\n","2. черные спереди\n","3. белые спереди\n","4. черные сзади\n","5. серебристые спереди\n","6. прочие (на фото есть желтый цвет)\n","7. синие\n","8. красные \n","9. зеленые"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clusters_visualiser(X_vdc_color, y_vdc_color, vdc_color_name)"]},{"cell_type":"markdown","metadata":{},"source":["1. серебристые\n","2. белые \n","3. черные \n","4. цветные"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clusters_visualiser(X_vdc_type, y_vdc_type, vdc_type_name) "]},{"cell_type":"markdown","metadata":{},"source":["1. спортивные?\n","2. грузовые и внедорожники\n","3. легковые"]},{"cell_type":"markdown","metadata":{},"source":["### Метод Аггломеративной кластеризации"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["show_clusters_and_scores(AgglomerativeClustering, sample_data=True) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_agglomerative_clustering(data, n_clusters, cut_size=5000):\n","    i_from = list(range(0, \n","                        data.shape[0], \n","                        cut_size))\n","    i_to = list(range(cut_size, \n","                      data.shape[0], \n","                      cut_size)) + [data.shape[0]]\n","\n","    y = []\n","    \n","    for i, j in zip(i_from, i_to):\n","        X = data[i:j]\n","        \n","        model = AgglomerativeClustering(n_clusters=n_clusters)\n","        y_ = model.fit_predict(X).tolist()\n","        \n","        [y.append(label) for label in y_]\n","    \n","    return np.array(y) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_effnet = train_agglomerative_clustering(X_effnet, 2)\n","print_series(effnet_name, y_effnet)\n","\n","clusters_visualiser(X_effnet, y_effnet, effnet_name) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_osnet = train_agglomerative_clustering(X_osnet, 9)\n","print_series(osnet_name, y_osnet)\n","\n","clusters_visualiser(X_osnet, y_osnet, osnet_name) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_vdc_color = train_agglomerative_clustering(X_vdc_color, 3) \n","print_series(vdc_color_name, y_vdc_color)\n","\n","clusters_visualiser(X_vdc_color, y_vdc_color, vdc_color_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_vdc_type = train_agglomerative_clustering(X_vdc_type, 3)\n","print_series(vdc_type_name, y_vdc_type) \n","\n","clusters_visualiser(X_vdc_type, y_vdc_type, vdc_type_name) "]},{"cell_type":"markdown","metadata":{},"source":["*Аггломеративная кластеризация не показала достаточной эффективности*"]},{"cell_type":"markdown","metadata":{},"source":["## Метод Гауссовой смеси"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["show_clusters_and_scores(GaussianMixture, rs=RS, sample_data=True) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_gaussianmixture(X, n):\n","    model = GaussianMixture(n_components=n, random_state=RS)\n","    y = model.fit_predict(X)\n","    \n","    return y "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_effnet = train_gaussianmixture(X_effnet, 2)\n","print_series(effnet_name, y_effnet)\n","\n","clusters_visualiser(X_effnet, y_effnet, effnet_name) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_osnet = train_gaussianmixture(X_osnet, 7)\n","print_series(osnet_name, y_osnet)\n","\n","clusters_visualiser(X_osnet, y_osnet, osnet_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_vdc_color = train_gaussianmixture(X_vdc_color, 2)\n","print_series(vdc_color_name, y_vdc_color)\n","\n","clusters_visualiser(X_vdc_color, y_vdc_color, vdc_color_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_vdc_type = train_gaussianmixture(X_vdc_type, 5)\n","print_series(vdc_type_name, y_vdc_type) \n","\n","clusters_visualiser(X_vdc_type, y_vdc_type, vdc_type_name)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
