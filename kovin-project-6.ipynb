{"cells":[{"cell_type":"markdown","metadata":{},"source":["# <center> Кластеризация изображений транспортных средств"]},{"cell_type":"markdown","metadata":{},"source":["## Импорт библиотек"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-04T12:56:27.447874Z","iopub.status.busy":"2023-09-04T12:56:27.447447Z","iopub.status.idle":"2023-09-04T12:56:30.190327Z","shell.execute_reply":"2023-09-04T12:56:30.189218Z","shell.execute_reply.started":"2023-09-04T12:56:27.447839Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.cluster import MiniBatchKMeans, AgglomerativeClustering, DBSCAN\n","from sklearn.mixture import GaussianMixture\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import warnings \n","import pickle\n","\n","plt.style.use('ggplot')\n","warnings.simplefilter(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Знакомство со структурой данных"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-09-04T12:56:30.192466Z","iopub.status.busy":"2023-09-04T12:56:30.191971Z","iopub.status.idle":"2023-09-04T12:57:28.655783Z","shell.execute_reply":"2023-09-04T12:57:28.654622Z","shell.execute_reply.started":"2023-09-04T12:56:30.192438Z"},"trusted":true},"outputs":[],"source":["desc_path = 'data/descriptors/'\n","\n","effnet_data = pickle.load(open(desc_path+'efficientnet-b7.pickle', 'rb')) \n","osnet_data = pickle.load(open(desc_path+'osnet.pickle', 'rb'))\n","vdc_color_data = pickle.load(open(desc_path+'vdc_color.pickle', 'rb'))\n","vdc_type_data = pickle.load(open(desc_path+'vdc_type.pickle', 'rb'))\n","\n","effnet_name = 'EfficientNet'\n","osnet_name = 'OSNet'\n","vdc_color_name = 'VDC color regression'\n","vdc_type_name = 'VDC type classification'\n","\n","additional_message = ''\n","\n","print_data = lambda name, data: print(f'{name}{additional_message}:\\n {data}', '\\n', \n","                                      f'{data.shape[0]} rows, {data.shape[1]} columns')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["EfficientNet:\n"," [[ 0.07503103  0.31044954  0.27607426 ...  0.04311841  0.14683516\n","  -0.01805534]\n"," [ 0.10779837 -0.09006837  0.46310857 ... -0.09697916 -0.06330508\n","  -0.14716671]\n"," [ 0.13423096  0.05216528 -0.06171756 ...  0.12218092  0.08158205\n","   0.39443853]\n"," ...\n"," [ 0.06453541 -0.10203699  0.00895808 ...  0.00603626  0.11986581\n","   0.05312547]\n"," [-0.05973828  0.23829538 -0.07465039 ... -0.08202351  0.15163201\n","  -0.02009818]\n"," [ 0.01950189 -0.0498712  -0.13986556 ... -0.04308372 -0.04311737\n","   0.01135673]] \n"," 416314 rows, 2560 columns\n"]}],"source":["print_data(effnet_name, effnet_data)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["OSNet:\n"," [[0.         0.         0.         ... 0.73321515 0.         5.9709315 ]\n"," [0.         0.         0.         ... 2.2757177  0.         0.9488349 ]\n"," [0.         0.         0.         ... 1.7822491  0.         3.8112872 ]\n"," ...\n"," [0.         0.         0.         ... 3.7419376  0.         3.0801718 ]\n"," [0.         0.         0.         ... 0.         0.         4.114627  ]\n"," [0.         0.         0.         ... 2.0509033  0.         4.501842  ]] \n"," 416314 rows, 512 columns\n"]}],"source":["print_data(osnet_name, osnet_data) "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["VDC color regression:\n"," [[-0.9374271  -0.05472132  0.596811   ... -0.84743977 -0.4845666\n","  -0.3595275 ]\n"," [-0.57900274  0.07446817  0.80651325 ... -0.77683306 -0.72354007\n","  -0.47988674]\n"," [-0.58707464 -0.48330888  0.7987211  ... -0.31682357 -0.68277246\n","  -0.43500212]\n"," ...\n"," [-0.68106437 -0.19239229  0.6374473  ... -0.30040908 -0.4964002\n","  -0.34969243]\n"," [-0.62768203 -0.03720693  0.5353278  ... -0.5285779  -0.64782023\n","  -0.3015691 ]\n"," [-0.535808   -0.02395482  0.5972718  ... -0.5199307  -0.42627487\n","  -0.10311161]] \n"," 416314 rows, 128 columns\n"]}],"source":["print_data(vdc_color_name, vdc_color_data)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["VDC type classification:\n"," [[0.02564181 0.00200849 0.14198549 ... 0.1284933  0.15204279 0.01345227]\n"," [0.00805954 0.         0.13719751 ... 0.07015307 0.13695519 0.05582581]\n"," [0.03058972 0.03774371 0.01926565 ... 0.05357384 0.02103408 0.06070706]\n"," ...\n"," [0.04895582 0.02745031 0.03123017 ... 0.02064629 0.11645781 0.27788612]\n"," [0.06860567 0.         0.04587822 ... 0.0141571  0.30611995 0.30511984]\n"," [0.0245354  0.01397088 0.02359578 ... 0.         0.23655881 0.34663343]] \n"," 416314 rows, 512 columns\n"]}],"source":["print_data(vdc_type_name, vdc_type_data) "]},{"cell_type":"markdown","metadata":{},"source":["> *Посмотрев на размерности каждой из заданных матриц, можно сказать, что нейросеть EfficientNet описывает изображения наиболее подробным образом - на 2560 дескрипторов. На мой взгляд, в конечном итоге, именно на дескрипторах этой модели кластеризация будет наиболее точной.*"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-09-04T12:57:28.657383Z","iopub.status.busy":"2023-09-04T12:57:28.657069Z","iopub.status.idle":"2023-09-04T12:57:29.241593Z","shell.execute_reply":"2023-09-04T12:57:29.240452Z","shell.execute_reply.started":"2023-09-04T12:57:28.657356Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>paths</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>veriwild\\1\\00001\\000001.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>veriwild\\1\\00001\\000002.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>veriwild\\1\\00001\\000003.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>veriwild\\1\\00001\\000004.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>veriwild\\1\\00001\\000005.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         paths\n","0  veriwild\\1\\00001\\000001.jpg\n","1  veriwild\\1\\00001\\000002.jpg\n","2  veriwild\\1\\00001\\000003.jpg\n","3  veriwild\\1\\00001\\000004.jpg\n","4  veriwild\\1\\00001\\000005.jpg"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["img_paths = pd.read_csv('data/images_paths.csv')\n","\n","img_paths.head()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>paths</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>data/raw_data/veriwild/1/00001/000001.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>data/raw_data/veriwild/1/00001/000002.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>data/raw_data/veriwild/1/00001/000003.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>data/raw_data/veriwild/1/00001/000004.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>data/raw_data/veriwild/1/00001/000005.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                       paths\n","0  data/raw_data/veriwild/1/00001/000001.jpg\n","1  data/raw_data/veriwild/1/00001/000002.jpg\n","2  data/raw_data/veriwild/1/00001/000003.jpg\n","3  data/raw_data/veriwild/1/00001/000004.jpg\n","4  data/raw_data/veriwild/1/00001/000005.jpg"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["img_paths['paths'] = ('data/raw_data/' + \n","                      img_paths['paths']\n","                      .apply(lambda x: x.replace('\\\\', '/')))\n","\n","img_paths.head()"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Преобразование, очистка и анализ данных"]},{"cell_type":"markdown","metadata":{},"source":["Признаки, найденные с помощью некоторых моделей, исчисляются тысячами, что довольно много. Производить кластеризацию на таком большом количестве признаков, которые были сформированы исходными моделями глубокого обучения, довольно сложно и затратно по времени. \n","\n","Понизим размерность исходных дескрипторов с помощью соответствующих методов. Можно уменьшить размерность входных данных до 100 или 200 признаков — этого будет достаточно, чтобы произвести кластеризацию."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-09-04T12:57:29.244497Z","iopub.status.busy":"2023-09-04T12:57:29.244149Z","iopub.status.idle":"2023-09-04T12:57:29.249502Z","shell.execute_reply":"2023-09-04T12:57:29.248267Z","shell.execute_reply.started":"2023-09-04T12:57:29.244467Z"},"trusted":true},"outputs":[],"source":["RS = 12 # random_state\n","additional_message = ' standardised and decomposed'\n","\n","def standardise_and_decompose(data, n_components):\n","    scaler = StandardScaler()\n","    data_scaled = scaler.fit_transform(data)\n","    \n","    decomposer = PCA(n_components=n_components, random_state=RS)\n","    data_decomposed = decomposer.fit_transform(data_scaled)\n","    \n","    return data_decomposed"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["EfficientNet standardised and decomposed:\n"," [[-6.392846   -8.0306     -5.1712832  ... -0.93881094 -0.29507932\n","   0.06558389]\n"," [ 0.11269631 -6.6813912  -8.274391   ... -0.8033253  -3.220662\n","  -2.0273364 ]\n"," [27.236897   -2.4911914  10.262569   ...  0.5977275   1.1912907\n","   3.0495672 ]\n"," ...\n"," [-0.22228312 10.032676    5.341996   ... -0.24986169  0.57753813\n","  -2.9753752 ]\n"," [ 8.232424   -6.2188783  -9.6312275  ...  1.4211016  -2.505131\n","   1.0491748 ]\n"," [-2.5488615  -8.760049    2.8383548  ... -2.9031942   3.630205\n","   2.4233046 ]] \n"," 416314 rows, 200 columns\n"]}],"source":["X_effnet = standardise_and_decompose(effnet_data, n_components=200) \n","\n","print_data(effnet_name, X_effnet) "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["OSNet standardised and decomposed:\n"," [[ 8.894714    3.883797   -0.4352938  ...  0.8419724   0.7836857\n","  -0.15880808]\n"," [10.033609   10.559829    1.350923   ...  0.22478826  1.2867533\n","  -1.2770413 ]\n"," [11.764579   -4.6160383  11.434134   ...  0.349415    0.48223457\n","  -0.3112529 ]\n"," ...\n"," [11.598919    3.9592345  -1.319604   ...  1.0375335  -0.73153156\n","   0.02393902]\n"," [11.684401    3.8797033  -1.6715256  ... -0.5221352  -0.5155513\n","  -0.02083515]\n"," [13.776697    1.4445709  -1.3631305  ...  0.5121564   0.3617846\n","   0.20612915]] \n"," 416314 rows, 100 columns\n"]}],"source":["X_osnet = standardise_and_decompose(osnet_data, n_components=100)\n","\n","print_data(osnet_name, X_osnet) "]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["VDC color regression standardised and decomposed:\n"," [[ 6.9730935  -2.0009577  -0.6357882  ...  0.42695466  1.03495\n","  -0.51705647]\n"," [10.329828    3.5165734   1.5414443  ... -0.9301343   0.54043657\n","   0.34933636]\n"," [ 5.9565578  -2.7572248  -0.75980663 ...  0.0823462  -0.3642026\n","  -0.7040139 ]\n"," ...\n"," [ 6.6750607  -1.7448863  -0.9150222  ... -0.1772642  -0.41230237\n","   0.27644104]\n"," [ 6.9716234   1.6645024   2.2677023  ...  0.30425635 -0.11063747\n","   0.17154838]\n"," [ 5.348204   -0.83681786 -0.19558297 ... -0.4723452  -0.6409422\n","   0.1239072 ]] \n"," 416314 rows, 50 columns\n"]}],"source":["X_vdc_color = standardise_and_decompose(vdc_color_data, n_components=50)\n","\n","print_data(vdc_color_name, X_vdc_color)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["VDC type classification standardised and decomposed:\n"," [[-18.531847     6.516248   -10.038634   ...  -0.11448457   0.02874413\n","    0.3911034 ]\n"," [-12.080046     0.31760624  -7.800973   ...  -0.34514797  -0.14387304\n","    0.06541659]\n"," [-12.882711    -1.9050103    0.27547884 ...  -0.10448331   0.14534083\n","    0.09299384]\n"," ...\n"," [ 13.293516   -10.875357     4.5444937  ...  -0.11473103  -0.11541691\n","   -0.41409087]\n"," [ 12.6623955   -9.151441    -2.4135375  ...   0.15878738   0.10404526\n","   -0.16025425]\n"," [ 13.219351   -11.179386    -0.7091788  ...  -0.32942897   0.25565085\n","   -0.21128808]] \n"," 416314 rows, 100 columns\n"]}],"source":["X_vdc_type = standardise_and_decompose(vdc_type_data, n_components=100)\n","\n","print_data(vdc_type_name, X_vdc_type) "]},{"cell_type":"markdown","metadata":{},"source":["## 3. Моделирование и оценка качества модели"]},{"cell_type":"markdown","metadata":{},"source":["После предобработки исходных данных произведите кластеризацию для каждого набора дескрипторов.\n","\n","Для решения задачи используйте несколько различных методов, подобрав оптимальное количество кластеров для каждого метода и варианта дескрипторов.\n","\n","В качестве метрики для подбора оптимального количества кластеров используйте внутренние меры:\n","* индекс Калински — Харабаса (`calinski_harabasz_score`) \n","* индекс Дэвиса — Болдина (`davies_bouldin_score`)"]},{"cell_type":"markdown","metadata":{},"source":["## Поиск выбросов"]},{"cell_type":"markdown","metadata":{},"source":["Для поиска выбросов попробуем следующий алгоритм:"]},{"cell_type":"markdown","metadata":{},"source":["#### 1. Визуализация изображений из полученных кластеров"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def plot_samples_images(label, data=img_paths, nrows=3, ncols=3):\n","    \"\"\"Функция для визуализации нескольких \n","       случайных изображений из кластера cluster_label.\n","       Пути до изображений и метки кластеров должны быть \n","       представлены в виде DataFrame со столбцами \"paths\" и \"cluster\".\n","\n","    Args:\n","        data (DataFrame): таблица с разметкой изображений и соответствующих им кластеров\n","        cluster_label (int): номер кластера изображений\n","        nrows (int, optional): количество изображений по строкам таблицы (по умолчанию 3)\n","        ncols (int, optional): количество изображений по столбцам (по умолчанию 3)\n","    \"\"\"\n","    \n","    # Фильтруем данные по номеру кластера\n","    samples_indexes = np.array(data[data['cluster'] == label].index)\n","    # Перемешиваем результаты\n","    np.random.shuffle(samples_indexes)\n","    # Составляем пути до изображений\n","    paths = data.loc[samples_indexes, 'paths']\n","\n","    # Создаём фигуру и набор координатных плоскостей\n","    fig, axes = plt.subplots(nrows, ncols, figsize=(8, 5))\n","    fig.suptitle(f\"Cluster {label}\", fontsize=16)\n","    \n","    # Создаём циклы по строкам и столбцам в таблице с координатными плоскостями\n","    for i in range(nrows):\n","        for j in range(ncols):\n","            # Определяем индекс пути до изображения\n","            path_idx = i * ncols + j\n","            if path_idx >= len(paths):\n","                break\n","                \n","            # Извлекаем путь до изображения\n","            path = paths.iloc[path_idx]\n","            \n","            # Читаем изображение\n","            img = plt.imread(path)\n","            \n","            # Убираем пометки координатных осей\n","            axes[i,j].axis('off')\n","            # Отображаем его на соответствующей координатной плоскости\n","            axes[i,j].imshow(img)\n","\n","\n","get_sample = lambda X, n=5000: pd.DataFrame(X).sample(n, \n","                                                      random_state=RS, \n","                                                      ignore_index=False)\n","\"\"\"_summary_\"\"\"\n","\n","\n","def tsne_visualiser(X, y, title, n_components):\n","    \"\"\"mhbffajmherb\n","\n","    Args:\n","        X (_type_): _description_\n","        y (_type_): _description_\n","        title (_type_): _description_\n","        n_components (_type_): _description_\n","\n","    Returns:\n","        _type_: _description_\n","    \"\"\"\n","    \n","    X_sample = get_sample(X)\n","    \n","    tsne_decomposer = TSNE(n_components=n_components, \n","                           random_state=RS, \n","                           n_jobs=-1)\n","    \n","    X_tsne = tsne_decomposer.fit_transform(X_sample)\n","    \n","    tsne_data = pd.DataFrame(X_tsne, columns=['x', 'y', 'z'])\n","    tsne_data['label'] = y\n","    \n","    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n","    palette = 'muted'\n","    \n","    sns.scatterplot(tsne_data, \n","                    x='x', y='y', hue='label', \n","                    palette=palette, \n","                    ax=ax[0])\n","    sns.scatterplot(tsne_data, \n","                    x='y', y='z', hue='label', \n","                    palette=palette, \n","                    ax=ax[1])\n","    sns.scatterplot(tsne_data, \n","                    x='x', y='z', hue='label', \n","                    palette=palette, \n","                    ax=ax[2])\n","\n","    fig.suptitle(title)\n","    fig.show()\n","    \n","    return tsne_data\n","\n","\n","def clusters_visualiser(X, y, title, n_components=3, data=img_paths):\n","    tsne_visualiser(X, y, title, n_components)\n","    \n","    data['cluster'] = y\n","\n","    for i in np.unique(y):\n","        plot_samples_images(i) "]},{"cell_type":"markdown","metadata":{},"source":["#### 2. Настройка параметров алгоритма DBSCAN (eps)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["eps_space = (np.linspace(0.01, \n","                         100, \n","                         100, \n","                         dtype=float)\n","             .round(2)\n","             .tolist())\n","\n","def train_dbscan():\n","    model = DBSCAN(eps=eps, n_jobs=-1)\n","    y = model.fit_predict(X_sample)\n","\n","\n","\n","def tune_dbscan_eps(X, eps_space):\n","    X_sample = get_sample(X)\n","    \n","    eps_list = []\n","    chs_list = []\n","    dbs_list = []\n","\n","    for eps in eps_space:\n","        model = DBSCAN(eps=eps, n_jobs=-1)\n","        y = model.fit_predict(X_sample)\n","        \n","        if len(np.unique(y)) == 1:\n","            continue\n","        else:\n","            eps_list.append(eps)\n","            chs_list.append(calinski_harabasz_score(X_sample, y))\n","            dbs_list.append(davies_bouldin_score(X_sample, y))\n","            \n","    eps_data = pd.DataFrame({'chs': chs_list, \n","                             'dbs': dbs_list}, \n","                            index=eps_list)\n","    \n","    chs_eps = (eps_data\n","               .sort_values('chs', ascending=False)\n","               .index[0])\n","    dbs_eps = (eps_data\n","               .sort_values('dbs', ascending=True)\n","               .index[0])\n","    \n","    return chs_eps, dbs_eps"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print_series = lambda name, data: print(f'{name}{additional_message}:\\n {data}', '\\n', \n","                                        pd.Series(data).value_counts().to_dict(), '\\n')\n","\n","\n","\n","\n","\n","def n_visualiser(X, space, train_func, title, n_components=3):\n","    \n","    \n","    \n","    y = train_func(X, n_clusters)\n","    print_series(title, y)\n","    \n","    clusters_visualiser(X, y, title, n_components)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def dbscan_visualiser(X, title, eps):\n","    clustering = DBSCAN(eps=eps)\n","    \n","    X_sample = get_sample(X)\n","    y = clustering.fit_predict(X_sample)\n","    \n","    clusters_visualiser(X, y, title)\n","\n","    \n","def outliers_visualiser(X, title, eps_space=eps_space):\n","    eps = tune_dbscan_eps(X, eps_space)\n","    \n","    dbscan_visualiser(X, title+' (Calinski-Harabasz)', eps[0])\n","    dbscan_visualiser(X, title+' (Davies-Bouldin)', eps[1])"]},{"cell_type":"markdown","metadata":{},"source":["#### 3. Визуализация полученных кластеров и их изображений"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["outliers_visualiser(X_effnet, effnet_name) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["outliers_visualiser(X_osnet, osnet_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["outliers_visualiser(X_vdc_color, vdc_color_name) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["outliers_visualiser(X_vdc_type, vdc_type_name) "]},{"cell_type":"markdown","metadata":{},"source":["## 3.1 Метод MiniBatchKMeans"]},{"cell_type":"markdown","metadata":{},"source":["Поскольку исходных данных много, могут возникнуть проблемы с оперативной памятью и скоростью работы, например при использовании классического алгоритма `K-means`, можно воспользоваться реализацией `MiniBatchKMeans`. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-04T13:00:22.741548Z","iopub.status.busy":"2023-09-04T13:00:22.741157Z","iopub.status.idle":"2023-09-04T13:02:13.309018Z","shell.execute_reply":"2023-09-04T13:02:13.307549Z","shell.execute_reply.started":"2023-09-04T13:00:22.741512Z"},"trusted":true},"outputs":[],"source":["def get_clustering_scores(model, data, c_range, rs=None):\n","    chs_list = []\n","    dbs_list = []\n","    \n","    for c in c_range:\n","        \n","        if rs is not None:\n","            model_ = model(c, random_state=RS)    \n","        else: \n","            model_ = model(c)\n","        \n","        labels = model_.fit_predict(data)\n","        \n","        chs_list.append(calinski_harabasz_score(data, labels))\n","        dbs_list.append(davies_bouldin_score(data, labels))\n","    \n","    return chs_list, dbs_list\n","\n","\n","def get_n_clusters(df, aggf):\n","    c_dict = {}\n","    \n","    for col in df.columns:\n","        if aggf == 'max':\n","            c_dict[col] = (df[col]\n","                           .sort_values(ascending=False)\n","                           .index[0])\n","        if aggf == 'min':\n","            c_dict[col] = (df[col]\n","                           .sort_values(ascending=True)\n","                           .index[0])\n","        \n","    return c_dict"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["datasets = {'efficientnet': X_effnet, \n","            'osnet': X_osnet, \n","            'vdc_color_reg': X_vdc_color, \n","            'vdc_type_cl': X_vdc_type}\n","\n","clusters = list(range(2, 11))\n","\n","\n","def show_clusters_and_scores(model,\n","                             datasets=datasets, \n","                             clusters=clusters, \n","                             rs=None, \n","                             sample_data=False):\n","    \n","    chs_df = pd.DataFrame(index=clusters)\n","    chs_name = 'Calinski-Harabasz'\n","    \n","    dbs_df = pd.DataFrame(index=clusters) \n","    dbs_name = 'Davies-Bouldin'\n","    \n","    for name, data in datasets.items():\n","        if sample_data:\n","            data = get_sample(data)\n","        \n","        if rs is not None:\n","            chs_df[name] = get_clustering_scores(model, data, clusters, rs)[0]\n","            dbs_df[name] = get_clustering_scores(model, data, clusters, rs)[1]\n","        else: \n","            chs_df[name] = get_clustering_scores(model, data, clusters)[0]\n","            dbs_df[name] = get_clustering_scores(model, data, clusters)[1]\n","    \n","    metsics = pd.DataFrame(data=[get_n_clusters(chs_df, 'max'), \n","                                 get_n_clusters(dbs_df, 'min')], \n","                           index=[chs_name, dbs_name])\n","    \n","    return metsics\n","\n","\n","show_clusters_and_scores(MiniBatchKMeans, rs=RS)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["additional_message = ' labels and their counts'\n","\n","\n","\n","\n","def train_minibatchkmeans(X, n):\n","    mbkm = MiniBatchKMeans(n_clusters=n, random_state=RS)\n","    y = mbkm.fit_predict(X)\n","    \n","    return y\n","\n","\n","def n_visualiser(X, n_clusters, train_func, title, n_components=3):\n","    y = train_func(X, n_clusters)\n","    print_series(title, y)\n","    \n","    clusters_visualiser(X, y, title, n_components)"]},{"cell_type":"markdown","metadata":{},"source":["### Интерпретация кластеров"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clusters_visualiser(X_effnet, y_effnet, effnet_name) "]},{"cell_type":"markdown","metadata":{},"source":["*Разница между кластерами очень слабая, так как на графике точки очень плотно расположены друг к другу и образуют четкий эллипс в его центре.*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clusters_visualiser(X_osnet, y_osnet, osnet_name) "]},{"cell_type":"markdown","metadata":{},"source":["0. прочие\n","1. белые сзади\n","2. черные спереди\n","3. белые спереди\n","4. черные сзади\n","5. серебристые спереди\n","6. прочие (на фото есть желтый цвет)\n","7. синие\n","8. красные \n","9. зеленые"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clusters_visualiser(X_vdc_color, y_vdc_color, vdc_color_name)"]},{"cell_type":"markdown","metadata":{},"source":["1. серебристые\n","2. белые \n","3. черные \n","4. цветные"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clusters_visualiser(X_vdc_type, y_vdc_type, vdc_type_name) "]},{"cell_type":"markdown","metadata":{},"source":["1. спортивные?\n","2. грузовые и внедорожники\n","3. легковые"]},{"cell_type":"markdown","metadata":{},"source":["### Метод Аггломеративной кластеризации"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["show_clusters_and_scores(AgglomerativeClustering, sample_data=True) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_agglomerative_clustering(data, n_clusters, cut_size=5000):\n","    i_from = list(range(0, \n","                        data.shape[0], \n","                        cut_size))\n","    i_to = list(range(cut_size, \n","                      data.shape[0], \n","                      cut_size)) + [data.shape[0]]\n","\n","    y = []\n","    \n","    for i, j in zip(i_from, i_to):\n","        X = data[i:j]\n","        \n","        model = AgglomerativeClustering(n_clusters=n_clusters)\n","        y_ = model.fit_predict(X).tolist()\n","        \n","        [y.append(label) for label in y_]\n","    \n","    return np.array(y) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_effnet = train_agglomerative_clustering(X_effnet, 2)\n","print_series(effnet_name, y_effnet)\n","\n","clusters_visualiser(X_effnet, y_effnet, effnet_name) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_osnet = train_agglomerative_clustering(X_osnet, 9)\n","print_series(osnet_name, y_osnet)\n","\n","clusters_visualiser(X_osnet, y_osnet, osnet_name) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_vdc_color = train_agglomerative_clustering(X_vdc_color, 3) \n","print_series(vdc_color_name, y_vdc_color)\n","\n","clusters_visualiser(X_vdc_color, y_vdc_color, vdc_color_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_vdc_type = train_agglomerative_clustering(X_vdc_type, 3)\n","print_series(vdc_type_name, y_vdc_type) \n","\n","clusters_visualiser(X_vdc_type, y_vdc_type, vdc_type_name) "]},{"cell_type":"markdown","metadata":{},"source":["*Аггломеративная кластеризация не показала достаточной эффективности*"]},{"cell_type":"markdown","metadata":{},"source":["## Метод Гауссовой смеси"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["show_clusters_and_scores(GaussianMixture, rs=RS, sample_data=True) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_gaussianmixture(X, n):\n","    model = GaussianMixture(n_components=n, random_state=RS)\n","    y = model.fit_predict(X)\n","    \n","    return y "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_effnet = train_gaussianmixture(X_effnet, 2)\n","print_series(effnet_name, y_effnet)\n","\n","clusters_visualiser(X_effnet, y_effnet, effnet_name) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_osnet = train_gaussianmixture(X_osnet, 7)\n","print_series(osnet_name, y_osnet)\n","\n","clusters_visualiser(X_osnet, y_osnet, osnet_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_vdc_color = train_gaussianmixture(X_vdc_color, 2)\n","print_series(vdc_color_name, y_vdc_color)\n","\n","clusters_visualiser(X_vdc_color, y_vdc_color, vdc_color_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_vdc_type = train_gaussianmixture(X_vdc_type, 5)\n","print_series(vdc_type_name, y_vdc_type) \n","\n","clusters_visualiser(X_vdc_type, y_vdc_type, vdc_type_name)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
